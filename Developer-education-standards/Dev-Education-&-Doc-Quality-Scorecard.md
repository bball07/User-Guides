# Developer Education & Documentation Quality Scorecard

**Purpose**  
This scorecard evaluates the effectiveness of developer-facing documentation and education materials against real-world usability, adoption, and sustainability standards. It is designed to surface risk, prioritize improvements, and guide roadmap decisions.

---

## Scoring Method
- Each category is scored on a **0–5 scale**
- **Category Score = Average Score × Weight**
- **Total Possible Score: 100**

### Score Scale
- **0** – Missing or harmful  
- **1** – Present but ineffective  
- **2** – Incomplete or inconsistent  
- **3** – Adequate baseline  
- **4** – Strong and effective  
- **5** – Exemplary / best-in-class  

---

## 1. Outcome Alignment (20%)
**Does the documentation enable real developer work?**

| Criteria | Score (0–5) |
|--------|-------------|
| Clear, action-based goals | ☐ |
| Goals map to real developer tasks | ☐ |
| Success is observable in implementation | ☐ |

**Category Score:** ____ / 20

---

## 2. Audience & Inclusivity (15%)
**Is the content usable by a diverse developer audience?**

| Criteria | Score (0–5) |
|--------|-------------|
| Assumes varied experience levels | ☐ |
| Clear prerequisites or entry points | ☐ |
| Inclusive, plain language | ☐ |
| Easy self-selection of relevant content | ☐ |

**Category Score:** ____ / 15

---

## 3. Learning Experience Design (15%)
**Is cognitive load intentionally managed?**

| Criteria | Score (0–5) |
|--------|-------------|
| Modular, task-sized content | ☐ |
| Consumable between real work tasks | ☐ |
| Progressive technical depth | ☐ |
| Clear introductions and summaries | ☐ |

**Category Score:** ____ / 15

---

## 4. Developer-Centered Practice (15%)
**Does the content respect developer time and autonomy?**

| Criteria | Score (0–5) |
|--------|-------------|
| Optional depth and skippable sections | ☐ |
| Realistic, production-relevant examples | ☐ |
| Focus on smallest useful skill shift | ☐ |

**Category Score:** ____ / 15

---

## 5. Structure & Reusability (15%)
**Can this documentation be reused as a job aid?**

| Criteria | Score (0–5) |
|--------|-------------|
| Clear objectives and prerequisites | ☐ |
| Explicit step-by-step flow | ☐ |
| Contextualized code or configuration | ☐ |
| Explains outcomes and side effects | ☐ |
| Includes an experimentation step | ☐ |
| Clear recap and signposting | ☐ |

**Category Score:** ____ / 15

---

## 6. Feedback, Iteration & Sustainability (10%)
**Is documentation treated as a living system?**

| Criteria | Score (0–5) |
|--------|-------------|
| Visible feedback channels | ☐ |
| Confusion is captured and analyzed | ☐ |
| Iteration driven by usage data | ☐ |

**Category Score:** ____ / 10

---

## 7. Meta-Skill Enablement (10%)
**Does this help developers learn more efficiently over time?**

| Criteria | Score (0–5) |
|--------|-------------|
| Encourages safe experimentation | ☐ |
| Models systematic debugging or evaluation | ☐ |
| Teaches how to assess tools and docs | ☐ |

**Category Score:** ____ / 10

---

## Final Score

| Total Score | Interpretation |
|------------|----------------|
| **85–100** | Best-in-class developer experience |
| **70–84** | Strong foundation, targeted improvements needed |
| **50–69** | Functional but high-friction |
| **Below 50** | High risk to adoption and scalability |

**Overall Score:** ____ / 100

---

## Consultant Summary

**Primary Risks Identified:**  
-  

**Highest-Impact Opportunities:**  
-  

**Recommended Next Actions (30–60 days):**  
-  

---

## Usage Guidance
- **Authors:** self-review before publishing  
- **Reviewers:** shared framework for consistent feedback  
- **Leads:** quality bar and prioritization tool  

